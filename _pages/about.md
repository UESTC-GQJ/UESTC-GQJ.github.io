---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I received a Bachelor's degree in Computer Science and Technology from the School of Computer Science, Beijing University of Technology (BJUT), in 2020. Currently, I am a third-year PhD student in Computer Science and Technology at the School of Computer Science, University of Electronic Science and Technology of China (UESTC), advised by [Zhao Kang](https://scholar.google.com/citations?user=T_yCaN4AAAAJ&hl=zh-CN).

My research interest includes large language models, information extraction, and natural language processing. I have published more than 10 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?hl=zh-CN&user=Jn7inOcAAAAJ'>google scholar citations <strong><span id='total_cit'>40</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?hl=zh-CN&user=Jn7inOcAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# ğŸ”¥ News
- *2025.11*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by AAAI 2026 (Oral).
- *2025.06*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ICCV 2025. 
- *2025.04*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by IJCAI 2025.
- *2025.04*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ICIC 2025.
- *2025.03*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ICDE 2025.
- *2024.11*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by COLING 2025.
- *2024.09*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by EMNLP 2024 Findings.
- *2023.04*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by IJCNN 2023.
- ...

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2025</div><img src='images/IJCAI2025.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Bridging Generative and Discriminative Learning: Few-Shot Relation Extraction via Two-Stage Knowledge-Guided Pre-training](https://ijcai-preprints.s3.us-west-1.amazonaws.com/2025/6581.pdf)

**Quanjiang Guo**, Jinchuan Zhang, Sijie Wang, Ling Tian, Zhao Kangâœ‰ï¸, Bin Yan, Weidong Xiao

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=Jn7inOcAAAAJ&sortby=pubdate&citation_for_view=Jn7inOcAAAAJ:WF5omc3nYNoC) <strong><span class='show_paper_citations' data='Jn7inOcAAAAJ:WF5omc3nYNoC'></span></strong>
- WAIT..... 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">COLING 2025</div><img src='images/COLING2025.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[BANER: Boundary-aware LLMs for few-shot named entity recognition](https://aclanthology.org/2025.coling-main.691.pdf)

**Quanjiang Guo**, Yihong Dong, Ling Tian, Zhao Kangâœ‰ï¸, Yu Zhang, Sijie Wang

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=Jn7inOcAAAAJ&sortby=pubdate&citation_for_view=Jn7inOcAAAAJ:eQOLeE2rZwMC) <strong><span class='show_paper_citations' data='Jn7inOcAAAAJ:eQOLeE2rZwMC'></span></strong>
- WAIT..... 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCNN 2023</div><img src='images/IJCNN2023.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[TieFake: Title-Text Similarity and Emotion-Aware Fake News Detection](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10191858)

**Quanjiang Guo**, Zhao Kangâœ‰ï¸, Ling Tian, Zhouguo Chen

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=Jn7inOcAAAAJ&sortby=pubdate&citation_for_view=Jn7inOcAAAAJ:9yKSN-GCB0IC) <strong><span class='show_paper_citations' data='Jn7inOcAAAAJ:9yKSN-GCB0IC'></span></strong>
- WAIT..... 
</div>
</div>
- [CodeBoost: Boosting Code LLMs by Squeezing Knowledge from Code Snippets with RL](https://arxiv.org/pdf/2508.05242?), Sijie Wang, **Quanjiang Guo**, Kai Zhao, Yawei Zhang, Xin Li, Xiang Li, Siqi Li, Rui She, Shangshu Yu, Wee Peng Tay, **underview**
- [UAVScenes: A Multi-Modal Dataset for UAVs](https://arxiv.org/pdf/2507.22412?), Sijie Wang, Siqi Li, Shenghai Yuan, Rui She, **Quanjiang Guo**, JinXuan Zheng, Ong Kang Howe, Leonrich Chandra, Shrivarshann Srijeyan, Aditya Sivadas, Toshan Aggarwal, Heyuan Liu, Hongming Zhang, Chujie Chen, Junyu Jiang, Lihua Xie, Wee Peng Tay, **ICCV 2025**
- [ENGCL: Graph Contrastive Learning via Ego-Preservation and Neighborhood Learning](https://link.springer.com/chapter/10.1007/978-981-96-9849-3_6), Wenqiang Du, **Quanjiang Guo**, Ming Jia, Ke Yan, Zhao Kang, **ICIC 2025**
- [Historically relevant event structuring for temporal knowledge graph reasoning](https://arxiv.org/pdf/2405.10621), Jinchuan Zhang, Ming Sun, Chong Mu, Jinhao Zhang, **Quanjiang Guo**, Ling Tian, **ICDE 2025**
- Semantic Anchor-aligned Multimodal Data Augmentation for Low-Resource Multimodal Information Extraction, **Quanjiang Guo**, Jiazhou Pan, Chong Mu, Ling Tian, Hui Gao, zhao kang, **underview**
- [Contrast Sample Pre-selection for Augmentation-Free Graph Contrastive Learning](https://ieeexplore.ieee.org/abstract/document/11010726/), Wenqiang Du, **Quanjiang Guo**, Jiaxin Li, Zhao Kang, **ISCAIT 2025**
- [Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering](https://aclanthology.org/2024.findings-emnlp.524.pdf), Yu Zhang, Kehai Chen, Xuefeng Bai, **Quanjiang Guo**, Min Zhang, **EMNLP 2024**
- [Research on Distant Supervision Relation Extraction based on Attention Graph Enhancement and Dynamic Loss](https://dl.acm.org/doi/abs/10.1145/3677779.3677802), Liu Yue, Shengquan Liu, Ming Zhao, **Quanjiang Guo**, **CMNM 2024**
- [Entity Relation Interactive Graph Convolutional Network for Knowledge Embedding](https://ieeexplore.ieee.org/abstract/document/10202435/), Yang He, Bei Hui, **Quanjiang Guo**, Ling Tian, Dong Liu, **DSDE 2024**

# ğŸ– Honors and Awards
- *2025.06*, CETCâ€“UESTC Third-Class Scholarship.
- *2025.05*, Bronze Medal of China Collegiate Algorithm Design & Programming Chanllenge Contest.
- *2024.10*, Second-Class Doctoral Scholarship.
- *2024.09*, Gold Award, University Track â€“ Sichuan Division, 2024 Ascend AI Innovation Competition.
- *2024.08*, Silver Award of Sichuan International "Internet plus" Undergraduate Innovation and Entrepreneurship Competition. 
- *2023.10*, Third-Class Doctoral Scholarship.
- *2023.06*, 2023 Student Travel Grant Award of International Neural Network Society.
- *2022.11*, First Prize of the "Feijiang Cup" Chongqing First Artificial Intelligence Innovation Competition.
- *2022.09*, Gold Award of Sichuan International "Internet plus" Undergraduate Innovation and Entrepreneurship Competition. 
- *2017.09*, Outstanding Cadre Award at the School Level. 
- *2017.09*, National Inspirational Scholarship. 

# ğŸ“– Educations
- *2021.09 - 2027.06 (now)*, University of Electronic Science and Technology of China (USETC), computer science and technology. 
- *2016.09 - 2020.06*, Beijing University of Technology (BJUT), computer science and technology. 

# ğŸ’¬ Academic Services
- *Conference Reviewer*, ACL, EMNLP, ACM MM, ICME, ACM MM Asia, IJCNN. 
- *Journal Reviewer*, TASLP.

# ğŸ’» Internships
- *2019.06 - 2019.07*, Institute of Remote Sensing and Digital Earthï¼ŒChinese Academy of Sciences, Beijing, China.
- *2022.08 - 2023.07*, 30th Research Institute of China Electronics Technology Group Corporation, Chengdu, China.

<div class="visitor-map">
  <script type="text/javascript" id="clstr_globe"
          src="//clustrmaps.com/globe.js?d=fPNK-MMo9z8qUaehTJoQkQa5q9UUDerCQ5fkoaowWvc">
  </script>
</div>

<style>
  /* å¤–å±‚å®¹å™¨ï¼Œä¿æŒ 1:1 æ¯”ä¾‹ï¼ˆæ­£æ–¹å½¢ï¼‰ */
  .visitor-map {
    width: 30%;
    max-width: 400px;   /* æœ€å¤§å®½åº¦ï¼Œå¯æ”¹ */
    aspect-ratio: 1 / 1;
    margin: 0 auto;     /* å±…ä¸­ */
    position: relative;
  }

  /* Clustrmaps è‡ªåŠ¨ç”Ÿæˆçš„ canvas å¡«å……å®¹å™¨ */
  .visitor-map canvas {
    width: 30% !important;
    height: 30% !important;
    display: block;
  }
</style>
